{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equipped-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "traditional-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "params = {\n",
    "    'axes.labelsize': 8,\n",
    "    'font.size': 8,\n",
    "    'legend.fontsize': 10,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'text.usetex': False,\n",
    "    'figure.figsize': [4.5, 4.5],\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': True,\n",
    "}\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "mpl.rcParams.update(params)\n",
    "mpl.use(\"pgf\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tired-dining",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/jupyter-data/flowtorch/flowtorch/params/dense_autoregressive.py:160: UserWarning: DenseAutoregressive input_dim = 1. Consider using an affine transformation instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfb72839a394a5cae88529c7846b8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1873\n"
     ]
    }
   ],
   "source": [
    "import beanmachine.ppl as bm\n",
    "import torch.distributions as dist\n",
    "import torch\n",
    "\n",
    "base_dist = dist.Normal(torch.zeros(1), torch.ones(1))\n",
    "target = dist.Cauchy(0, 1)\n",
    "\n",
    "import flowtorch.bijectors\n",
    "import flowtorch.params\n",
    "\n",
    "flow = flowtorch.bijectors.AffineAutoregressive(\n",
    "    flowtorch.params.DenseAutoregressive(hidden_dims=(32,32,32))\n",
    ")\n",
    "new_dist, params = flow(base_dist)\n",
    "\n",
    "import torch.optim\n",
    "optimizer = torch.optim.Adam(params.parameters(), lr=1e-3)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "for _ in tqdm(range(int(1e3))):\n",
    "    optimizer.zero_grad()\n",
    "    samples = new_dist.rsample((1000,))\n",
    "    log_q = new_dist.log_prob(samples)\n",
    "    log_p = target.log_prob(samples)\n",
    "    elbo = log_p - log_q\n",
    "    loss = -elbo.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    tqdm.write(f\"Loss: {loss:.4f}\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "antique-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f6cbd17fb9406799c02704196ccf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training iterations'), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([0.0824], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import beanmachine.ppl as bm\n",
    "import torch.nn as nn\n",
    "\n",
    "@bm.random_variable\n",
    "def tgt():\n",
    "    return target\n",
    "\n",
    "from beanmachine.ppl.experimental.vi.variational_infer import (\n",
    "    MeanFieldVariationalInference,\n",
    ")\n",
    "\n",
    "def on_iter(it, loss, vi_dicts):\n",
    "    if it % 10 == 0:\n",
    "        tqdm.write(f\"Loss: {loss}\", end='')\n",
    "\n",
    "vi_dicts = MeanFieldVariationalInference().infer(\n",
    "    queries=[tgt()],\n",
    "    observations={},\n",
    "    num_iter=int(500),\n",
    "    progress_bar=True,\n",
    "    flow=lambda: flowtorch.bijectors.AffineAutoregressive(\n",
    "        flowtorch.params.DenseAutoregressive(hidden_dims=(32,32,32))\n",
    "    ),\n",
    "    lr=1e-3,\n",
    "    on_iter=on_iter,\n",
    "    base_dist=dist.StudentT,\n",
    "    base_args={\n",
    "        'df': nn.Parameter(torch.tensor([5.0]).log()),\n",
    "        'loc': nn.Parameter(torch.tensor([0.0])),\n",
    "        'scale': nn.Parameter(torch.tensor([1.0])),\n",
    "    },\n",
    "    num_elbo_mc_samples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baking-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "\n",
    "default_cycler = (cycler(color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']) +\n",
    "                  cycler(linestyle=['-', '--', ':', '-.']))\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(5.5,2))\n",
    "\n",
    "xs = torch.linspace(-5, 5).unsqueeze(1)\n",
    "ax[0].plot(xs, new_dist.log_prob(xs).exp().detach())\n",
    "ax[0].plot(xs, vi_dicts(tgt()).log_prob(xs).exp().detach())\n",
    "ax[0].plot(xs, target.log_prob(xs).exp())\n",
    "ax[0].set_xlabel('$x$')\n",
    "ax[0].set_title('$p(x)$')\n",
    "\n",
    "xs = torch.linspace(0, 10).unsqueeze(1)\n",
    "ax[1].plot(xs, new_dist.log_prob(xs).exp().detach())\n",
    "ax[1].plot(xs, vi_dicts(tgt()).log_prob(xs).exp().detach())\n",
    "ax[1].plot(xs, target.log_prob(xs).exp())\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel('$x$')\n",
    "ax[1].set_title('$\\log p(x)$')\n",
    "\n",
    "import scipy.stats\n",
    "ax[2].hist(\n",
    "    [scipy.stats.kstest(lambda size: new_dist.sample((size,)).squeeze().numpy(), lambda x: target.cdf(torch.tensor(x)).numpy(), N=100).pvalue for _ in range(1000)],\n",
    "    #density=True,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax[2].hist(\n",
    "    #[scipy.stats.kstest(lambda size: vi_dicts(tgt()).sample((size,)).squeeze().numpy(), lambda x: target.cdf(torch.tensor(x)).numpy()).pvalue for _ in range(1000)],\n",
    "    [scipy.stats.kstest(lambda size: vi_dicts(tgt()).sample((size,)).squeeze().numpy(), lambda x: target.cdf(torch.tensor(x)).numpy(), N=100).pvalue for _ in range(1000)],\n",
    "    #density=True,\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax[2].set_title('K-S p-values')\n",
    "ax[2].set_ylabel('Count')\n",
    "ax[2].set_xlabel('$p$-value')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(['ADVI', 'ATAF', 'Target'], loc=\"center right\")\n",
    "fig.subplots_adjust(right=0.8)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compliant-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('fat_tail_ks.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-defensive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
